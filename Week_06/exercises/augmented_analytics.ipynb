{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Analytics with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import re\n",
    "import io\n",
    "import sys\n",
    "import json\n",
    "import openai\n",
    "import textwrap\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load OpenAI API key from credentials.json\n",
    "try:\n",
    "    with open('./data/credentials.json', encoding='utf-8') as f:\n",
    "        credentials = json.load(f)\n",
    "        api_key = credentials['openai']['api_key']\n",
    "except FileNotFoundError as exc:\n",
    "    raise ValueError(\n",
    "        \"Please provide OpenAI API key in the credentials.json file.\") from exc\n",
    "\n",
    "# Set up OpenAI API key\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import example data\n",
    "data = pd.read_csv('./data/apartments_data.csv', sep=';')\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to query GPT-3.5 for Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query GPT-3.5 for Python code\n",
    "def query_gpt(context, question):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a coding assistant. Provide Python code based on user queries.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {question}\\n\\nAlso, provide a short explanation of the result.\"}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=1500\n",
    "        )\n",
    "        full_response = response.choices[0].message['content']\n",
    "\n",
    "        # Extract code block using regular expression\n",
    "        code_match = re.search(r'```python(.*?)```', full_response, re.DOTALL)\n",
    "        if code_match:\n",
    "            code = code_match.group(1).strip()\n",
    "            \n",
    "            # Ensure the plot is saved in the static folder\n",
    "            code += \"\\nplt.savefig('./data/graphic.png')\\nplt.close()\"\n",
    "            explanation = full_response.split('Explanation:')[1].strip() if 'Explanation:' in full_response else \"No explanation provided.\"\n",
    "            return code, explanation\n",
    "        else:\n",
    "            return \"No code block found in the response.\", \"No explanation provided.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error querying GPT: {e}\", \"No explanation provided.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to query llama 3.2 using Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query an LLM using Ollama for Python code\n",
    "def query_ollama(context, question):\n",
    "    try:\n",
    "        response = subprocess.run(\n",
    "            [\"ollama\", \"run\", \"llama3.2:latest\", f\"{context}\\n\\nQuestion: {question}\"],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        full_response = response.stdout.strip()\n",
    "\n",
    "        # Extract code block using regex\n",
    "        code_match = re.search(r'```python(.*?)```', full_response, re.DOTALL)\n",
    "        if code_match:\n",
    "            code = code_match.group(1).strip()\n",
    "            explanation = full_response.split('Explanation:')[1].strip() if 'Explanation:' in full_response else \"No explanation provided.\"\n",
    "            return code, explanation\n",
    "        else:\n",
    "            return \"No code block found.\", \"No explanation provided.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error querying Ollama: {e}\", \"No explanation provided.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a CSV file\n",
    "def load_csv_file(file_path, nrows=None):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=';', nrows=nrows)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to execute Python code dynamically and capture the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute Python code dynamically and capture the output\n",
    "def execute_python_code(code, data=None):\n",
    "    local_scope = {'plt': plt}\n",
    "    if data is not None:\n",
    "        local_scope['data'] = data\n",
    "    try:\n",
    "        # Redirect stdout to capture print statements\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = io.StringIO()\n",
    "        exec(code, local_scope)\n",
    "        output = sys.stdout.getvalue()\n",
    "        \n",
    "        # Reset stdout\n",
    "        sys.stdout = old_stdout\n",
    "        \n",
    "        # Save the plot if it was created\n",
    "        if plt.get_fignums():\n",
    "            plt.savefig('./data/graphic.png')\n",
    "            plt.close()\n",
    "        \n",
    "        return output.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error executing code: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context\n",
    "context = \"import pandas as pd\\nimport matplotlib.pyplot as plt\\ndata = \" \\\n",
    "          \"pd.read_csv('./data/apartments_data.csv', sep=';')\\n\"\n",
    "          \n",
    "# Question\n",
    "question = \"Show a histogram of the price of apartments with <= 65 m2. Use 20 bins.\"\n",
    "\n",
    "# Query the LMM\n",
    "generated_code, explanation = query_gpt(context, question)\n",
    "\n",
    "# Wrap the text to a maximum width of 80 characters\n",
    "explanation_wrapped = textwrap.fill(explanation, width=80)\n",
    "\n",
    "# Print generated code\n",
    "print(\"Generated Python code:\")\n",
    "print(generated_code)\n",
    "\n",
    "# Print explanation\n",
    "print(\"\\nExplanation:\")\n",
    "print(explanation_wrapped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the generated Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the generated code\n",
    "try:\n",
    "    generated_code = generated_code.replace(\"figsize=(10, 6)\", \n",
    "                                            \"figsize=(7, 4)\")\n",
    "    generated_code = generated_code.replace(\"color='skyblue'\", \n",
    "                                            \"color='greenyellow'\") \n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Show the modified code\n",
    "print(\"\\nModified Python code:\")\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the generated Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the generated Python code\n",
    "local_vars = {}\n",
    "figure_created = False\n",
    "try:\n",
    "    exec(generated_code, globals(), local_vars)\n",
    "except Exception as e:\n",
    "    print(f\"Error executing generated code: {e}\")\n",
    "\n",
    "# Check the type of the result and display accordingly\n",
    "for var_name, var_value in local_vars.items():\n",
    "    if isinstance(var_value, plt.Figure):\n",
    "        print(f\"\\nFigure: {var_name}\")\n",
    "        var_value.show()\n",
    "        figure_created = True\n",
    "\n",
    "if not figure_created:\n",
    "    for var_name, var_value in local_vars.items():\n",
    "        if isinstance(var_value, pd.DataFrame):\n",
    "            print(f\"\\nDataFrame: {var_name}\")\n",
    "            print(var_value.head())\n",
    "        else:\n",
    "            print(f\"\\n{var_name}: {var_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter notebook --footer info-- (please always provide this at the end of each notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import socket\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
